{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# Import and Initialize Sentiment Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define location for config file\n",
    "sys.path.append('../../..')\n",
    "\n",
    "# Import Twitter API keys.\n",
    "from config import consumer_key, consumer_secret, access_token, access_token_secret, twitter_api_sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Twitter sometimes did not recognize/log mentions when requests were made using '@jxavie analyze: @target_user'\n",
    "# As a work around, a for loop was used to aggregate user mentions into a list, before using another for loop to \n",
    "# determine the target account by comparing the contents of the user mentions list to the screen name associated \n",
    "# with the API keys.  While this allows more flexibility in the syntax, requests are still limited one target account\n",
    "# and requires the inclusion of the word 'analyze'.\n",
    "\n",
    "# Define function to retrieve mentions and determine if sentiment analysis is requested\n",
    "def retrieve_mentions():\n",
    "    \n",
    "    # Initialize list to store mentions within a tweet\n",
    "    mentions = []\n",
    "    \n",
    "    # Request tweets containing mentions of screen name associated with API key\n",
    "    tweets = api.mentions_timeline()\n",
    "    \n",
    "    # Define tasks to perform if record of mentions found \n",
    "    try:\n",
    "\n",
    "        # Return latest tweet with mention\n",
    "        request = tweets[0]['text']\n",
    "\n",
    "        # Set all tweet characters to lower case\n",
    "        request_lower = request.lower()\n",
    "\n",
    "        # Determine tweet ID\n",
    "        #tweet_id = request[0]['id']\n",
    "\n",
    "        # Determine user making request for analysis\n",
    "        tweeter = tweets[0]['user']['screen_name']\n",
    "\n",
    "        # Use conditional to determine whether an analysis is requested\n",
    "        if (request_lower.find('analyze') != -1):\n",
    "\n",
    "            # Use for loop to determine users mentioned in tweet and append user handles to mentions list\n",
    "            for i in range(len(tweets[0]['entities']['user_mentions'])):\n",
    "                mentions.append(tweets[0]['entities']['user_mentions'][i]['screen_name'])\n",
    "\n",
    "            # Use for loop and condition to determine user to be analyzed\n",
    "            for i in range(len(mentions)):\n",
    "                if twitter_api_sn != mentions[i]:\n",
    "                    target_user = f'@{mentions[i]}'\n",
    "\n",
    "        # Set target_user value to null if no analysis is requested and print error message\n",
    "        else:\n",
    "            target_user = None\n",
    "            print('No analysis request found.')\n",
    "    \n",
    "    # Set return variables to none if no mentions record found and print error message\n",
    "    except:\n",
    "        target_user = None\n",
    "        tweeter = None\n",
    "        print(\"No tweets requesting analysis found.\")\n",
    "    \n",
    "    # Define variables to return\n",
    "    return target_user, tweeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to retrieve tweets from target account and store in a dataframe\n",
    "def retrieve_tweets(handle):\n",
    "    \n",
    "    # Initialize lists to store tweets and tweet information\n",
    "    user_sn = []\n",
    "    tweet_texts = []\n",
    "    tweet_time = []\n",
    "    \n",
    "    # Initialize lists for sentiments\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    neutral_list = []\n",
    "    negative_list = []\n",
    "    \n",
    "    # Loop through 1 pages of tweets for testing\n",
    "    # for x in range(1,2):\n",
    "    \n",
    "    # Loop through 25 pages of tweets (for a total of 500 tweets)\n",
    "    for x in range(1,26):\n",
    "        \n",
    "        # Retrieve tweets from home feed\n",
    "        public_tweets = api.user_timeline(handle, page=x, tweet_mode='extended')\n",
    "        \n",
    "        # Loop through tweets and store retrieved information in list\n",
    "        for tweet in public_tweets:\n",
    "            \n",
    "            # Store tweets and tweet information in appropriate lists\n",
    "            user_sn.append(tweet['user']['screen_name'])\n",
    "            tweet_texts.append(tweet['full_text'])\n",
    "            tweet_time.append(tweet['created_at'])\n",
    "            \n",
    "            #Run Vader Analysis on tweet\n",
    "            results = analyzer.polarity_scores(tweet['full_text'])\n",
    "            \n",
    "            # Add each value to the appropriate list\n",
    "            compound_list.append(results['compound'])\n",
    "            positive_list.append(results['pos'])\n",
    "            neutral_list.append(results['neu'])\n",
    "            negative_list.append(results['neg'])\n",
    "    \n",
    "    # Store tweets as an entry in a dictionary\n",
    "    tweets_df = pd.DataFrame([user_sn,tweet_texts,tweet_time,compound_list,positive_list,neutral_list,negative_list]).transpose()\n",
    "    tweets_df.columns = ['source','tweet','timestamp','compound','positive','neutral','negative']\n",
    "    \n",
    "    # Add tweet numbering\n",
    "    tweets_df = tweets_df.reset_index()\n",
    "    tweets_df['index'] = tweets_df['index'] + 1\n",
    "    tweets_df = tweets_df.rename(columns={'index':'tweet number'})\n",
    "    \n",
    "    # Convert unix timestamps to dates\n",
    "    tweets_df['timestamp'] = pd.to_datetime(tweets_df['timestamp'])\n",
    "\n",
    "    # Cast sentiment values as float\n",
    "    tweets_df['compound'] = tweets_df['compound'].astype('float')\n",
    "    tweets_df['positive'] = tweets_df['compound'].astype('float')\n",
    "    tweets_df['neutral'] = tweets_df['compound'].astype('float')\n",
    "    tweets_df['negative'] = tweets_df['compound'].astype('float')\n",
    "\n",
    "    # Create new column with formatted date\n",
    "    # news_df['date'] = news_df['timestamp'].map(lambda x: x.strftime('%m/%d/%y'))\n",
    "\n",
    "    # Truncate and Reorder columns of dataframe\n",
    "    tweets_df = tweets_df[['source','tweet number','tweet','timestamp','compound','positive','neutral','negative']]\n",
    "    \n",
    "    # Save dataframe as csv\n",
    "    tweets_df.to_csv(f'Output/{handle}_tweets.csv',index=False)\n",
    "    \n",
    "    # Print success message\n",
    "    print(f'Retrieved and analyzed 500 most recent tweets from {handle}.')\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to create plot\n",
    "def create_plot(handle, dataframe):\n",
    "\n",
    "    # Retrieve date\n",
    "    date_analysis = date.today().strftime(\"%m/%d/%y\")\n",
    "\n",
    "    # Specify size of plot\n",
    "    plt.rcParams['figure.dpi'] = 200\n",
    "\n",
    "    # Generate plot\n",
    "    fig, tweets_plot = plt.subplots()\n",
    "\n",
    "    # Define scatter plot data and settings for markers\n",
    "    tweets_plot.plot(dataframe['tweet number'], dataframe['compound'], label=handle, marker='o', markersize=4, linewidth=0.3) \n",
    "\n",
    "    # Define labels and formatting of plot\n",
    "    plt.title(f'Sentiment Analysis of Tweets ({date_analysis})', fontsize='small')\n",
    "    plt.xlabel('Tweets Ago', fontsize='x-small')\n",
    "    plt.ylabel('Tweet Polarity', fontsize='x-small')\n",
    "    plt.legend(loc='upper right', bbox_to_anchor=(1.2, 1), shadow=False, fontsize='xx-small', \n",
    "               title='Tweets', title_fontsize = 'x-small', frameon=False)\n",
    "\n",
    "    # Define tick mark locations\n",
    "    x_major_ticks = np.arange(500,-5,-100)\n",
    "    y_major_ticks = np.arange(-1,1.5,0.5)\n",
    "\n",
    "    # Set format for tick marks\n",
    "    plt.xticks(fontsize='x-small')\n",
    "    plt.yticks(fontsize='x-small')\n",
    "    tweets_plot.set_xticks(x_major_ticks)\n",
    "    tweets_plot.set_yticks(y_major_ticks)\n",
    "\n",
    "    # Define min and max value limits for x- and y-axes\n",
    "    plt.xlim(505, -5, 100)\n",
    "    plt.ylim(-1.05, 1.05, 0.5)\n",
    "\n",
    "    # Remove border around plot\n",
    "    tweets_plot.spines['top'].set_visible(False)\n",
    "    tweets_plot.spines['bottom'].set_visible(False)\n",
    "    tweets_plot.spines['right'].set_visible(False)\n",
    "    tweets_plot.spines['left'].set_visible(False)\n",
    "\n",
    "    # Remove tick marks\n",
    "    tweets_plot.tick_params(axis=u'both', which=u'both',length=0)\n",
    "\n",
    "    # Show grid\n",
    "    plt.grid(color='whitesmoke', alpha=1.5)\n",
    "\n",
    "    # Set plot background colot\n",
    "    tweets_plot.set_facecolor('lightgray')\n",
    "    \n",
    "    # Create variable to store figure name and location\n",
    "    plot_image = f'Output/{handle}_sentiment_plot.png'\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig(plot_image,bbox_inches='tight')\n",
    "\n",
    "    # Show figure\n",
    "    # plt.show()\n",
    "\n",
    "    # Print message\n",
    "    print(f'Plot of Vader Analysis on tweets by {handle} generated.')\n",
    "    \n",
    "    return plot_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to post status\n",
    "def tweet_plot(plot, handle, requestor):\n",
    "        \n",
    "    # Create a status update\n",
    "    # api.update_with_media(\"../Resources/too-much-big-data.jpg\", \"Testing...\")\n",
    "    api.update_with_media(plot, f'New Tweet Analysis: {handle} \\n(Thanks @{requestor} for the request!)')\n",
    "    \n",
    "    print(f'Vader Analysis plot for {handle} posted on twitter. \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User to analyze: @TheSimpsons\n",
      "Retrieved and analyzed 500 most recent tweets from @TheSimpsons.\n",
      "Plot of Vader Analysis on tweets by @TheSimpsons generated.\n",
      "Vader Analysis plot for @TheSimpsons posted on twitter. \n",
      "\n",
      "User to analyze: @HomerJSimpson\n",
      "Retrieved and analyzed 500 most recent tweets from @HomerJSimpson.\n",
      "Plot of Vader Analysis on tweets by @HomerJSimpson generated.\n",
      "Vader Analysis plot for @HomerJSimpson posted on twitter. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "User to analyze: @TheOnion\n",
      "Retrieved and analyzed 500 most recent tweets from @TheOnion.\n",
      "Plot of Vader Analysis on tweets by @TheOnion generated.\n",
      "Vader Analysis plot for @TheOnion posted on twitter. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "No new analysis request found. \n",
      "\n",
      "User to analyze: @Pontifex\n",
      "Retrieved and analyzed 500 most recent tweets from @Pontifex.\n",
      "Plot of Vader Analysis on tweets by @Pontifex generated.\n",
      "Vader Analysis plot for @Pontifex posted on twitter. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store users that have been analyzed\n",
    "analyzed_users = []\n",
    "# mention_id = []\n",
    "\n",
    "# Run infinite loop\n",
    "while(True):\n",
    "\n",
    "    # Run retrieve_mentions function\n",
    "    target_user, tweeter = retrieve_mentions()\n",
    "    \n",
    "    # Initialize counter variable\n",
    "    counter = 0\n",
    "    \n",
    "    # Use conditional to determine if analysis is to be performed\n",
    "    # Set analyze variable to True if analysis is to be performed; set to False otherwise \n",
    "    # If analysis is to be performed add target user handle to analyzed_users list\n",
    "    # Compare target_user to values stored in analyzed_users list.\n",
    "    # Analysis to be performed only if target_user has not already been analyzed\n",
    "    if target_user == None:\n",
    "        analyze = False\n",
    "    else:\n",
    "        if len(analyzed_users) == 0:\n",
    "            analyze = True\n",
    "            analyzed_users.append(target_user)\n",
    "        else:\n",
    "            for i in analyzed_users:\n",
    "                if i == target_user:\n",
    "                    counter += 1 \n",
    "            if counter == 0:\n",
    "                analyze = True\n",
    "                analyzed_users.append(target_user)\n",
    "            else:\n",
    "                analyze = False\n",
    "    \n",
    "    # Run functions if target user is identified; print error message otherwise\n",
    "    if analyze == True:\n",
    "        print(f'User to analyze: {target_user}')\n",
    "        tweets_df = retrieve_tweets(target_user)\n",
    "        plot_image = create_plot(target_user, tweets_df)\n",
    "        tweet_plot(plot_image, target_user, tweeter)\n",
    "    else:\n",
    "        print('No new analysis request found. \\n')\n",
    "    \n",
    "    # Set timer to re-run code after 5 minutes\n",
    "    time.sleep(5*60)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
